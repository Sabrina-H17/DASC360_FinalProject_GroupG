---
title: "EDA_GroupG"
output: html_document
date: "2025-10-13"
Authors: "Oksana Efron, Sabrina Hassan, Keri Gagnow"
---

```{r setup, include=FALSE}
library(readr)
library(psych)
library(corrplot)
library(ggplot2)
```
Importing our dataset into R Markdown:
```{r}
library(readr)

student_depression_dataset_CSV <- read_csv("student_depression_dataset_CSV.csv")

View(student_depression_dataset_CSV)
```
We found a data set that analyzes mental health trends and predictors among students, which we ended up naming to StudentDep. We reorganized the data so it has 70 cases and 17 variables. Our goal was to make sure that the variables was layed out properly and in a better fit so we could analyze.

```{r}
StudentDep <- student_depression_dataset_CSV[1:70, c("Gender", "Age", "City", "Profession", "Academic_Pressure", "Work_Pressure", "CGPA", "Study_Satisfaction", "Job_Satisfaction", "Sleep_Duration", "Dietary_Habits", "Degree", "Suicidal_Thoughts", "Work/Study_Hours", "Financial_Stress", "Family_History_of_Mental_Illness", "Depression")]
dim(StudentDep)
```

```{r}
StudentDep
```
What we did here is converted the categorical variables into numerical form, such as 1 for males and 0 for females. As well as for Dietary Habits and Sleep Duration, they were changed into numeric factors.

```{r}
# Making sure to change Gender to binary so its Males = 1, and Female = 0
StudentDep$Gender <- ifelse(StudentDep$Gender == "Male", 1, 0)

# Also doing this for Family History of Mental Illness converting, binary (Yes = 1, No = 0)
StudentDep$'Family_History_of_Mental_Illness' <- ifelse(StudentDep$'Family_History_of_Mental_Illness' == "Yes", 1, 0)

# Converting ordinal variables for Dietary Habits and Sleep Duration
StudentDep$ 'Dietary_Habits' <- as.numeric(factor(StudentDep$ 'Dietary_Habits',
                                                  levels = c("Unhealthy", "Average", "Healthy"),
                                                  ordered = TRUE))
StudentDep$ 'Sleep_Duration' <- as.numeric(factor(StudentDep$ 'Sleep_Duration',
                                                  levels = c("<5 hours", "5-6 hours", "6-8 hours", ">8 hours"),
                                                  ordered = TRUE))

# Converting Depression, for binary levels. Yes = 1 and No = 0
StudentDep$Depression <- ifelse(StudentDep$Depression == "Yes", 1, 0)

str(StudentDep)
```
```{r}
summary(StudentDep)
```
```{r}
dim(StudentDep)
```
We used boxplot to compare Academic Pressure and Study Satisfaction in  One-Dimensional Graphs
```{r}
ggplot(StudentDep) + geom_bar(aes(x = Academic_Pressure))

ggplot(StudentDep) + geom_bar(aes(x = Study_Satisfaction))
```




For here we made sure to have variables that are predictors, and variables that are response variables.

```{r}
# Predictor Variables
X <- StudentDep[, c("Gender", "Age", "Academic_Pressure", "Work_Pressure",
                    "CGPA", "Dietary_Habits", "Financial_Stress",
                    "Family_History_of_Mental_Illness")]
# Response Variables
Y <- StudentDep[, c("Depression", "Study_Satisfaction", "Job_Satisfaction", "Sleep_Duration")]
```
Used summary instead of describe()

```{r}
# Defining skewness and kurtosis
Skewness <- function(x) {
  n <- length(x)
  m3 <- sum((x - mean(x))^3)/n
  s3 <- sd(x)^3
}

kurtosis <- function(x) {
  n <- length(x)
  m4 <- sum((x - mean(x))^4)/n
  s4 <- sd(x)^4
  m4/s4
}


summary(StudentDep)
```
```{r}
# Calculating mean, Standard Deviation, Skewness, and Kurtosis
Vals <- sapply(StudentDep, is.numeric)
Data <- StudentDep[, Vals]

# Removing NA
Data <- Data[, colSums(is.na(Data)) < nrow(Data)]

SumStats <- data.frame(
  variable = colnames(Data),
  Mean = sapply(Data, mean),
  SD = sapply(Data, sd),
  Skewness = sapply(Data, Skewness),
  Kurtosis = sapply(Data, kurtosis)
)
print(SumStats)
```
Finding Covariance, Correlation, Scatter Plot Matrices. A issue faced would be that R is taking binary number that uses for example; Yes = 1, No = 0, into the correlation/covariance which is causing NA to be put into the dataset.

```{r}
# Covariance Matrix
Covar <- cov(Data)
print("Covariance Matrix:")
Covar
```

```{r}
# Correlation Matrix
Corr <- cor(Data, use = "pairwise.complete.obs")
print("Correlation Matrix:")
Corr
```

```{r}
# Scatter Plot
pairs(Data, pch = 19, main = "Scatter Plot")
```
```{r}
# Correlation Plot
corrplot(Corr,na.label = " ", method = "circle")
```
We noticed that there is a strong correlation along the main diagonal of the correlation plot

```{r}
pairs(Data, pch = 19, main = "Scatter matrix for outliers")
```

```{r}
# Mahalanobis distance
Vals <- sapply(Data, is.numeric)
Data <- Data[, Vals]

# Remove
Data <- na.omit(Data)

# Remove columns that have zero variance
Data <- Data[, apply(Data, 2, var) != 0]

center <- colMeans(Data)
Covar <- cov(Data)

mahalDist <- mahalanobis(Data, center, Covar)
Data$mahalanobis <- mahalDist


# Identify Outliers
CutOff <- qchisq(0.975, df = ncol(Data) - 1)
Outliers <- which(mahalDist > CutOff)
Outliers
```

When using the Mahalanobis distance and the use of scattterplots, we wanted to observe the correlation matrix and the outliers. We saw that certain variables may be weaker or stronger which depends between the variables. Also, can see that some extreme data points misshaped the strengths as well the binary variables caused the dataset to not look as appealing.



```{r}
# Predictor Variables
X <- StudentDep[, c("Gender", "Age", "Academic_Pressure", "Work_Pressure", "CGPA", "Dietary_Habits", "Financial_Stress", "Family_History_of_Mental_Illness")]

# Response Variables
Y <- StudentDep[, c("Depression", "Study_Satisfaction", "Job_Satisfaction", "Sleep_Duration")]

# Converting to numeric variables
X[] <- lapply(X, function(col) as.numeric((col)))
Y[] <- lapply(Y, function(col) as.numeric((col)))

# Removing rows with NA
X <- na.omit(X)
Y <- na.omit(Y)

# Keeping columns with zero variance
vars <- sapply(X, var, na.rm = TRUE)
X <- X[, vars > 0]
varsY <- sapply(Y, var, na.rm = TRUE)
Y <- Y[, !is.na(varsY) & varsY > 0]

# Correlation matrices
RX <- cor(X, use = "pairwise.complete.obs")


# Eigenvalues
EigX <- eigen(RX)


EigX$values

```

We will be using the Principal Component Analysis to see if an oblique or orthogonal rotation will be necessary for this data set. We will be setting our intrinsic dimensionality to be 4 for the Predictors, note that we were not able to find the loading matrices for the response variables as they were returning 0 despite all attempts
```{r}
R <- pca(r = RX, nfactors = 4, rotate = "varimax")$loadings[]
print("Orthogonal Rotation :")
R

R_1 <- pca(r = RX, nfactors = 4, rotate = "oblimin")$loadings[]

print("Oblique Rotation :")
R_1
```


